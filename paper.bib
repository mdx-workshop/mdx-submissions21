@misc{stoller2018waveunet,
      title={Wave-U-Net: A Multi-Scale Neural Network for End-to-End Audio Source Separation}, 
      author={Daniel Stoller and Sebastian Ewert and Simon Dixon},
      year={2018},
      eprint={1806.03185},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}

@misc{sawata2021all,
      title={All for One and One for All: Improving Music Separation by Bridging Networks}, 
      author={Ryosuke Sawata and Stefan Uhlich and Shusuke Takahashi and Yuki Mitsufuji},
      year={2021},
      eprint={2010.04228},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@article{Hennequin2020,
  doi = {10.21105/joss.02154},
  url = {https://doi.org/10.21105/joss.02154},
  year = {2020},
  publisher = {The Open Journal},
  volume = {5},
  number = {50},
  pages = {2154},
  author = {Romain Hennequin and Anis Khlif and Felix Voituret and Manuel Moussallam},
  title = {Spleeter: a fast and efficient music source separation tool with pre-trained models},
  journal = {Journal of Open Source Software}
}


@article{DBLP:journals/corr/abs-1711-00937,
  author    = {A{\"{a}}ron van den Oord and
               Oriol Vinyals and
               Koray Kavukcuoglu},
  title     = {Neural Discrete Representation Learning},
  journal   = {CoRR},
  volume    = {abs/1711.00937},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.00937},
  eprinttype = {arXiv},
  eprint    = {1711.00937},
  timestamp = {Mon, 13 Aug 2018 16:48:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-00937.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{https://doi.org/10.1111/mice.12363,
author = {Gao, Yuqing and Mosalam, Khalid M.},
title = {Deep Transfer Learning for Image-Based Structural Damage Recognition},
journal = {Computer-Aided Civil and Infrastructure Engineering},
volume = {33},
number = {9},
pages = {748-768},
doi = {https://doi.org/10.1111/mice.12363},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12363},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/mice.12363},
abstract = {Abstract This article implements the state-of-the-art deep learning technologies for a civil engineering application, namely recognition of structural damage from images. Inspired by ImageNet Challenge and the development of computer hardware, the concept of Structural ImageNet is proposed herein with four naïve baseline recognition tasks: component type identification, spalling condition check, damage level evaluation, and damage type determination. A relatively small number of images (2,000) are selected from the Structural ImageNet and manually labeled according to the four recognition tasks. In order to avoid overfitting, Transfer Learning (TL) based on VGGNet (Visual Geometry Group) is introduced and applied using two different strategies, namely feature extractor and fine-tuning. Two experiments are designed based on properties of these two strategies to find the relative optimal model parameters and scope of application. Models obtained by both strategies indicate the promising recognition results and different application potentials where feature extractor and fine-tuning can be respectively used for preliminary analysis and for further improvement. These results also reveal the potential uses of deep TL in image-based structural damage recognition.},
year = {2018}
}


@article{HAN201843,
title = {A new image classification method using CNN transfer learning and web data augmentation},
journal = {Expert Systems with Applications},
volume = {95},
pages = {43-56},
year = {2018},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2017.11.028},
url = {https://www.sciencedirect.com/science/article/pii/S0957417417307844},
author = {Dongmei Han and Qigang Liu and Weiguo Fan},
keywords = {Feature transferring, Data augmentation, Convolutional neural network, Feature representation, Parameter fine-tuning, Bayesian optimization},
abstract = {Since Convolutional Neural Network (CNN) won the image classification competition 202 (ILSVRC12), a lot of attention has been paid to deep layer CNN study. The success of CNN is attributed to its superior multi-scale high-level image representations as opposed to hand-engineering low-level features. However, estimating millions of parameters of a deep CNN requires a large number of annotated samples, which currently prevents many superior deep CNNs (such as AlexNet, VGG, ResNet) being applied to problems with limited training data. To address this problem, a novel two-phase method combining CNN transfer learning and web data augmentation is proposed. With our method, the useful feature presentation of pre-trained network can be efficiently transferred to target task, and the original dataset can be augmented with the most valuable Internet images for classification. Our method not only greatly reduces the requirement of a large training data, but also effectively expand the training dataset. Both of method features contribute to the considerable over-fitting reduction of deep CNNs on small dataset. In addition, we successfully apply Bayesian optimization to solve the tuff problem, hyper-parameter tuning, in network fine-tuning. Our solution is applied to six public small datasets. Extensive experiments show that, comparing to traditional methods, our solution can assist the popular deep CNNs to achieve better performance. Particularly, ResNet can outperform all the state-of-the-art models on six small datasets. The experiment results prove that the proposed solution will be the great tool for dealing with practice problems which are related to use deep CNNs on small dataset.}
}

@article{DBLP:journals/corr/abs-1910-10683,
  author    = {Colin Raffel and
               Noam Shazeer and
               Adam Roberts and
               Katherine Lee and
               Sharan Narang and
               Michael Matena and
               Yanqi Zhou and
               Wei Li and
               Peter J. Liu},
  title     = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text
               Transformer},
  journal   = {CoRR},
  volume    = {abs/1910.10683},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.10683},
  eprinttype = {arXiv},
  eprint    = {1910.10683},
  timestamp = {Fri, 05 Feb 2021 15:43:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-10683.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@misc{MUSDB18HQ,
  author       = {Rafii, Zafar and
                  Liutkus, Antoine and
                  Fabian-Robert St{\"o}ter and
                  Mimilakis, Stylianos Ioannis and
                  Bittner, Rachel},
  title        = {{MUSDB18-HQ} - an uncompressed version of MUSDB18},
  month        = dec,
  year         = 2019,
  doi          = {10.5281/zenodo.3338373},
  url          = {https://doi.org/10.5281/zenodo.3338373}
}

@misc{raffel2020exploring,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2020},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Oord2014TransferLB,
  title={Transfer Learning by Supervised Pre-training for Audio-based Music Classification},
  author={A{\"a}ron van den Oord and S. Dieleman and B. Schrauwen},
  booktitle={ISMIR},
  year={2014}
}

@INPROCEEDINGS{7472128,  author={Lim, Hyungjun and Kim, Myung Jong and Kim, Hoirin},  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Cross-acoustic transfer learning for sound event classification},   year={2016},  volume={},  number={},  pages={2504-2508},  doi={10.1109/ICASSP.2016.7472128}}

@article{Shor_2020,
   title={Towards Learning a Universal Non-Semantic Representation of Speech},
   url={http://dx.doi.org/10.21437/Interspeech.2020-1242},
   DOI={10.21437/interspeech.2020-1242},
   journal={Interspeech 2020},
   publisher={ISCA},
   author={Shor, Joel and Jansen, Aren and Maor, Ronnie and Lang, Oran and Tuval, Omry and Quitry, Félix de Chaumont and Tagliasacchi, Marco and Shavitt, Ira and Emanuel, Dotan and Haviv, Yinnon},
   year={2020},
   month={Oct}
}

@misc{razavi2019generating,
      title={Generating Diverse High-Fidelity Images with VQ-VAE-2}, 
      author={Ali Razavi and Aaron van den Oord and Oriol Vinyals},
      year={2019},
      eprint={1906.00446},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dhariwal2020jukebox,
      title={Jukebox: A Generative Model for Music}, 
      author={Prafulla Dhariwal and Heewoo Jun and Christine Payne and Jong Wook Kim and Alec Radford and Ilya Sutskever},
      year={2020},
      eprint={2005.00341},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@article{Stoeter2019,
  doi = {10.21105/joss.01667},
  url = {https://doi.org/10.21105/joss.01667},
  year = {2019},
  publisher = {The Open Journal},
  volume = {4},
  number = {41},
  pages = {1667},
  author = {Fabian-Robert Stöter and Stefan Uhlich and Antoine Liutkus and Yuki Mitsufuji},
  title = {Open-Unmix - A Reference Implementation for Music Source Separation},
  journal = {Journal of Open Source Software}
}

@article{DBLP:journals/corr/abs-1909-01174,
  author    = {Alexandre D{\'{e}}fossez and
               Nicolas Usunier and
               L{\'{e}}on Bottou and
               Francis R. Bach},
  title     = {Demucs: Deep Extractor for Music Sources with extra unlabeled data
               remixed},
  journal   = {CoRR},
  volume    = {abs/1909.01174},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.01174},
  eprinttype = {arXiv},
  eprint    = {1909.01174},
  timestamp = {Mon, 09 Nov 2020 08:50:24 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-01174.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{musdb18-hq,
  author       = {Rafii, Zafar and
                  Liutkus, Antoine and
                  Stöter, Fabian-Robert and
                  Mimilakis, Stylianos Ioannis and
                  Bittner, Rachel},
  title        = {MUSDB18-HQ - an uncompressed version of MUSDB18},
  month        = aug,
  year         = 2019,
  doi          = {10.5281/zenodo.3338373},
  url          = {https://doi.org/10.5281/zenodo.3338373}
}

@misc{mitsufuji2021music,
      title={Music Demixing Challenge at ISMIR 2021}, 
      author={Yuki Mitsufuji and Giorgio Fabbro and Stefan Uhlich and Fabian-Robert Stöter},
      year={2021},
      eprint={2108.13559},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}
